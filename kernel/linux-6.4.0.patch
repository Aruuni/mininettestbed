diff --git a/include/linux/tcp.h b/include/linux/tcp.h
index 40e08abc6aa1..ab488ad038cf 100644
--- a/include/linux/tcp.h
+++ b/include/linux/tcp.h
@@ -452,6 +452,24 @@ struct tcp_sock {
 	 */
 	struct request_sock __rcu *fastopen_rsk;
 	struct saved_syn *saved_syn;
+
+
+	/* DeepCC Parameters */
+    u8 deepcc_enable; /* 1 => Only enable periodic reports and setting cwnd.
+					   * 2 => (above) + enable deepcc pacing rate calculation
+                       */
+    struct {
+		u32 min_urtt;
+		u32 avg_urtt;
+		u32 cnt;
+		u64	avg_thr;		/* average throughput */
+		u32	thr_cnt;		/* Number of sampled throughput for averaging it*/
+		u32 pre_lost;		/* Total Number of Previously lost packets*/
+	} deepcc_api;
+
+	/* Orca: min. cwnd*/
+	u32  cwnd_min;
+	/* End of DeepCC Parameters */
 };
 
 enum tsq_enum {
diff --git a/include/net/tcp.h b/include/net/tcp.h
index fbe88c5d76bd..5fdaf09f4bda 100644
--- a/include/net/tcp.h
+++ b/include/net/tcp.h
@@ -246,6 +246,8 @@ void tcp_time_wait(struct sock *sk, int state, int timeo);
 /* sysctl variables for tcp */
 extern int sysctl_tcp_max_orphans;
 extern long sysctl_tcp_mem[3];
+extern unsigned int sysctl_tcp_bbr_init_cwnd;
+extern int sysctl_tcp_deepcc_enable;
 
 #define TCP_RACK_LOSS_DETECTION  0x1 /* Use RACK to detect losses */
 #define TCP_RACK_STATIC_REO_WND  0x2 /* Use static RACK reo wnd */
@@ -1136,7 +1138,11 @@ struct tcp_congestion_ops {
 	/* get info for inet_diag (optional) */
 	size_t (*get_info)(struct sock *sk, u32 ext, int *attr,
 			   union tcp_cc_info *info);
+	/*NATCP*/
+	void (*update_by_app)(struct sock *sk);
 
+	/*RL-C2TCP*/
+	void (*get_rate_sample)(struct sock *sk, const struct rate_sample *rs);
 	char 			name[TCP_CA_NAME_MAX];
 	struct module		*owner;
 	struct list_head	list;
@@ -1207,6 +1213,12 @@ static inline void tcp_ca_event(struct sock *sk, const enum tcp_ca_event event)
 	if (icsk->icsk_ca_ops->cwnd_event)
 		icsk->icsk_ca_ops->cwnd_event(sk, event);
 }
+/* From tcp_deepcc.c */
+void deepcc_init(struct sock * sk);
+size_t deepcc_get_info(struct sock *sk, u32 ext, int *attr,union tcp_cc_info *info);
+void deepcc_get_rate_sample(struct sock *sk, const struct rate_sample *rs);
+void deepcc_update_cwnd(struct sock *sk);
+void deepcc_pkts_acked(struct sock *sk, const struct ack_sample *sample);
 
 /* From tcp_cong.c */
 void tcp_set_ca_state(struct sock *sk, const u8 ca_state);
diff --git a/include/uapi/linux/inet_diag.h b/include/uapi/linux/inet_diag.h
index 82f8bd8f0d16..452055a335d0 100644
--- a/include/uapi/linux/inet_diag.h
+++ b/include/uapi/linux/inet_diag.h
@@ -158,6 +158,7 @@ enum {
 	INET_DIAG_CLASS_ID,	/* request as INET_DIAG_TCLASS */
 	INET_DIAG_MD5SIG,
 	INET_DIAG_ULP_INFO,
+	INET_DIAG_DEEPCCINFO,
 	INET_DIAG_SK_BPF_STORAGES,
 	INET_DIAG_CGROUP_ID,
 	INET_DIAG_SOCKOPT,
@@ -242,6 +243,26 @@ struct tcp_bbr_info {
 	__u32	bbr_extra_acked;	/* max excess packets ACKed in epoch */
 };
 
+/* INET_DIAG_DEEPCCINFO */
+
+struct tcp_deepcc_info {
+	__u32	min_rtt;		/* min-filtered RTT in uSec */
+	__u32	avg_urtt;		/* averaged RTT in uSec from the previous info request till now*/
+	__u32	cnt;		/* number of RTT samples used for averaging */
+	__u64	avg_thr;		/* average throughput Bytes per Sec*/
+	__u32	thr_cnt;		/* Number of sampled throughput for averaging it*/
+	__u32	cwnd;
+	__u32	pacing_rate;
+	__u32	lost_bytes;			/* Number of lost Bytes (from the last monitored phase to now!)*/
+	__u32	srtt_us;	/* smoothed round trip time << 3 in usecs */
+	__u32	snd_ssthresh;	/* Slow start size threshold		*/
+	__u32	packets_out;	/* Packets which are "in flight"	*/
+	__u32	retrans_out;	/* Retransmitted packets out		*/
+	__u32	max_packets_out;  /* max packets_out in last window */
+	__u32 	mss_cache;
+};
+
+
 /* TCP BBR congestion control bbr_phase as reported in netlink/ss stats. */
 enum tcp_bbr_phase {
 	BBR_PHASE_INVALID		= 0,
@@ -258,5 +279,6 @@ union tcp_cc_info {
 	struct tcpvegas_info	vegas;
 	struct tcp_dctcp_info	dctcp;
 	struct tcp_bbr_info	bbr;
+	struct tcp_deepcc_info	deepcc;
 };
 #endif /* _UAPI_INET_DIAG_H_ */
diff --git a/include/uapi/linux/sysctl.h b/include/uapi/linux/sysctl.h
index 8981f00204db..7b1a14f463f2 100644
--- a/include/uapi/linux/sysctl.h
+++ b/include/uapi/linux/sysctl.h
@@ -426,6 +426,10 @@ enum
 	NET_TCP_ALLOWED_CONG_CONTROL=123,
 	NET_TCP_MAX_SSTHRESH=124,
 	NET_TCP_FRTO_RESPONSE=125,
+	
+	/* Variables for Learning-based Congestion Control */
+	NET_TCP_BBR_INIT_CWND=136,
+	NET_TCP_DEEPCC=161,
 };
 
 enum {
diff --git a/include/uapi/linux/tcp.h b/include/uapi/linux/tcp.h
index 77270053a5e3..9fe62a57dde3 100644
--- a/include/uapi/linux/tcp.h
+++ b/include/uapi/linux/tcp.h
@@ -134,6 +134,15 @@ enum {
 #define TCP_REPAIR_OFF		0
 #define TCP_REPAIR_OFF_NO_WP	-1	/* Turn off without window probes */
 
+/* Defining custom Socket TCP Options */
+#define TCP_CWND_CLAMP 42
+#define TCP_CWND 43
+#define TCP_DEEPCC_ENABLE 44
+#define TCP_CWND_CAP 45
+#define TCP_DEEPCC_INFO		46	/* Get Congestion Control (optional) DeepCC info */
+#define TCP_CWND_MIN		47
+
+/* End of Custom Socket Defines */
 struct tcp_repair_opt {
 	__u32	opt_code;
 	__u32	opt_val;
diff --git a/net/ipv4/Makefile b/net/ipv4/Makefile
index 4aeb3079ac3c..d7278b6bf0ca 100644
--- a/net/ipv4/Makefile
+++ b/net/ipv4/Makefile
@@ -10,6 +10,7 @@ obj-y     := route.o inetpeer.o protocol.o \
 	     tcp.o tcp_input.o tcp_output.o tcp_timer.o tcp_ipv4.o \
 	     tcp_minisocks.o tcp_cong.o tcp_metrics.o tcp_fastopen.o \
 	     tcp_rate.o tcp_recovery.o tcp_ulp.o \
+		 tcp_deepcc.o \
 	     tcp_offload.o tcp_plb.o datagram.o raw.o udp.o udplite.o \
 	     udp_offload.o arp.o icmp.o devinet.o af_inet.o igmp.o \
 	     fib_frontend.o fib_semantics.o fib_trie.o fib_notifier.o \
diff --git a/net/ipv4/sysctl_net_ipv4.c b/net/ipv4/sysctl_net_ipv4.c
index 2afb0870648b..7f66581adf17 100644
--- a/net/ipv4/sysctl_net_ipv4.c
+++ b/net/ipv4/sysctl_net_ipv4.c
@@ -1310,6 +1310,20 @@ static struct ctl_table ipv4_net_table[] = {
 		.mode		= 0644,
 		.proc_handler	= proc_dointvec_ms_jiffies,
 	},
+	{
+		.procname	= "tcp_bbr_init_cwnd",
+		.data		= &sysctl_tcp_bbr_init_cwnd,
+		.maxlen		= sizeof(unsigned int),
+		.mode		= 0644,
+		.proc_handler	= proc_douintvec,
+	},
+	{
+		.procname   = "tcp_deepcc",
+		.data       = &sysctl_tcp_deepcc_enable,
+		.maxlen     = sizeof(int),
+		.mode       = 0644,
+		.proc_handler   = proc_dointvec,	
+	},
 	{
 		.procname	= "tcp_pacing_ss_ratio",
 		.data		= &init_net.ipv4.sysctl_tcp_pacing_ss_ratio,
diff --git a/net/ipv4/tcp.c b/net/ipv4/tcp.c
index 497e442bd608..d6b98ff5a39c 100644
--- a/net/ipv4/tcp.c
+++ b/net/ipv4/tcp.c
@@ -292,6 +292,13 @@ EXPORT_PER_CPU_SYMBOL_GPL(tcp_orphan_count);
 long sysctl_tcp_mem[3] __read_mostly;
 EXPORT_SYMBOL(sysctl_tcp_mem);
 
+/* Enable Auto BW PROBING */
+unsigned int sysctl_tcp_bbr_init_cwnd __read_mostly = 4;
+EXPORT_SYMBOL(sysctl_tcp_bbr_init_cwnd);
+/* Learning-based CC */
+int sysctl_tcp_deepcc_enable __read_mostly = 0;
+EXPORT_SYMBOL(sysctl_tcp_deepcc_enable);
+
 atomic_long_t tcp_memory_allocated ____cacheline_aligned_in_smp;	/* Current allocated memory. */
 EXPORT_SYMBOL(tcp_memory_allocated);
 DEFINE_PER_CPU(int, tcp_memory_per_cpu_fw_alloc);
@@ -443,6 +450,9 @@ void tcp_init_sock(struct sock *sk)
 	tp->snd_ssthresh = TCP_INFINITE_SSTHRESH;
 	tp->snd_cwnd_clamp = ~0;
 	tp->mss_cache = TCP_MSS_DEFAULT;
+	
+	/* DeepCC Cwnd_coef init. to 1 */
+	tp->cwnd_min = 1;
 
 	tp->reordering = READ_ONCE(sock_net(sk)->ipv4.sysctl_tcp_reordering);
 	tcp_assign_congestion_control(sk);
@@ -3677,6 +3687,44 @@ int do_tcp_setsockopt(struct sock *sk, int level, int optname,
 			tcp_enable_tx_delay();
 		tp->tcp_tx_delay = val;
 		break;
+	/* DeepCC */
+	case TCP_DEEPCC_ENABLE:
+		tp->deepcc_enable = val;
+		break;
+	case TCP_CWND_CAP:
+		if (sysctl_tcp_bbr_init_cwnd <= val) {
+			tp->snd_cwnd_clamp = val;
+			tp->snd_cwnd = min(tp->snd_cwnd, tp->snd_cwnd_clamp);
+			tcp_push_pending_frames(sk);
+		}
+		break;
+
+	case TCP_CWND:
+		if (sysctl_tcp_bbr_init_cwnd <= val) {
+			tp->snd_cwnd = min(val, tp->snd_cwnd_clamp);
+		}
+		else{
+			tp->snd_cwnd = min(sysctl_tcp_bbr_init_cwnd, tp->snd_cwnd_clamp);
+		}
+		if (icsk->icsk_ca_ops->update_by_app) {
+			icsk->icsk_ca_ops->update_by_app(sk);
+		}
+		tcp_push_pending_frames(sk);
+		break;
+	case TCP_CWND_MIN:
+		if(sysctl_tcp_bbr_init_cwnd <= val) {
+			tp->cwnd_min =val;
+		}
+		else{
+			tp->cwnd_min =sysctl_tcp_bbr_init_cwnd;
+		}
+		tp->snd_cwnd = max(tp->cwnd_min, tp->snd_cwnd);
+		tp->snd_cwnd = min(tp->snd_cwnd, tp->snd_cwnd_clamp);
+		if (icsk->icsk_ca_ops->update_by_app) {
+			icsk->icsk_ca_ops->update_by_app(sk);
+		}
+		tcp_push_pending_frames(sk);
+		break;
 	default:
 		err = -ENOPROTOOPT;
 		break;
@@ -4044,6 +4092,28 @@ int do_tcp_getsockopt(struct sock *sk, int level,
 			return -EFAULT;
 		return 0;
 	}
+	/* TCP DeepCC Info */
+	case TCP_DEEPCC_INFO: {
+		const struct tcp_congestion_ops *ca_ops;
+		union tcp_cc_info info;
+		size_t sz = 0;
+		int attr;
+
+		if (copy_from_sockptr(&len, optlen, sizeof(int)))
+			return -EFAULT;
+
+		if(!tp->deepcc_enable && sysctl_tcp_deepcc_enable)
+			return -EFAULT;
+
+		sz = deepcc_get_info(sk, ~0U, &attr, &info);
+
+		len = min_t(unsigned int, len, sz);
+		if (copy_to_sockptr(optlen, &len, sizeof(int)))
+			return -EFAULT;
+		if (copy_to_sockptr(optval, &info, len))
+			return -EFAULT;
+		return 0;
+	}
 	case TCP_QUICKACK:
 		val = !inet_csk_in_pingpong_mode(sk);
 		break;
diff --git a/net/ipv4/tcp_cong.c b/net/ipv4/tcp_cong.c
index 66d40449b3f4..0f78d1156685 100644
--- a/net/ipv4/tcp_cong.c
+++ b/net/ipv4/tcp_cong.c
@@ -239,7 +239,9 @@ void tcp_assign_congestion_control(struct sock *sk)
 void tcp_init_congestion_control(struct sock *sk)
 {
 	struct inet_connection_sock *icsk = inet_csk(sk);
-
+	/* DeepCC Initialization */
+	tcp_sk(sk)->deepcc_enable = 0;
+	
 	tcp_sk(sk)->prior_ssthresh = 0;
 	tcp_sk(sk)->fast_ack_mode = 0;
 	if (icsk->icsk_ca_ops->init)
diff --git a/net/ipv4/tcp_cubic.c b/net/ipv4/tcp_cubic.c
index 0fd78ecb67e7..068185ce8d65 100644
--- a/net/ipv4/tcp_cubic.c
+++ b/net/ipv4/tcp_cubic.c
@@ -473,6 +473,14 @@ __bpf_kfunc static void cubictcp_acked(struct sock *sk, const struct ack_sample
 		hystart_update(sk, delay);
 }
 
+static inline void natcp_update_by_app(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	printk("natcp_update_by_app:snd_cwnd:%d\cwnd_clamp:%d\n",
+			tp->snd_cwnd,tp->snd_cwnd_clamp);
+	tp->snd_cwnd =min(tp->snd_cwnd,tp->snd_cwnd_clamp);
+}
+
 static struct tcp_congestion_ops cubictcp __read_mostly = {
 	.init		= cubictcp_init,
 	.ssthresh	= cubictcp_recalc_ssthresh,
@@ -480,6 +488,8 @@ static struct tcp_congestion_ops cubictcp __read_mostly = {
 	.set_state	= cubictcp_state,
 	.undo_cwnd	= tcp_reno_undo_cwnd,
 	.cwnd_event	= cubictcp_cwnd_event,
+	//S.A: To support NATCP
+	.update_by_app	= natcp_update_by_app,
 	.pkts_acked     = cubictcp_acked,
 	.owner		= THIS_MODULE,
 	.name		= "cubic",
diff --git a/net/ipv4/tcp_deepcc.c b/net/ipv4/tcp_deepcc.c
new file mode 100644
index 000000000000..70544d2e447c
--- /dev/null
+++ b/net/ipv4/tcp_deepcc.c
@@ -0,0 +1,149 @@
+/* Monitoring and Action Enforcer Blocks of DeepCC and Orca
+ *
+ * Author: Soheil Abbasloo <ab.soheil@nyu.edu>
+ *
+ * Generating useful states/information to be used by the Deep Reinforcement Learning Block.
+ *
+ * Orca is described in detail in:
+ *   "Classic Meets Modern: A Pragmatic Learning-Based Congestion Control for the Internet",
+ *   Soheil Abbasloo, Chen-Yu Yen, H. J. Chao. In Proc ACM SIGCOMM'20
+ *
+ * Orca's Repository:
+ *		https://github.com/soheil-ab/orca
+ *
+ * Copyright (C) 2020 Soheil Abbasloo <ab.soheil@nyu.edu>
+ */
+
+#include <net/tcp.h>
+#include <linux/inet_diag.h>
+
+/*
+ * Samplings required for DeepCC/Orca
+ */
+
+#define THR_SCALE_DEEPCC 24
+#define THR_UNIT_DEEPCC (1 << THR_SCALE_DEEPCC)
+
+void deepcc_init(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	tp->deepcc_api.min_urtt = 0;
+	tp->deepcc_api.cnt = 0;
+	tp->deepcc_api.avg_urtt = 0;
+	tp->deepcc_api.avg_thr = 0;
+	tp->deepcc_api.thr_cnt = 0;
+	tp->deepcc_api.pre_lost = 0;
+}
+
+size_t deepcc_get_info(struct sock *sk, u32 ext, int *attr,
+			      union tcp_cc_info *info)
+{
+	if (ext & (1 << (INET_DIAG_DEEPCCINFO - 1))) {
+		struct tcp_sock *tp = tcp_sk(sk);
+		memset(&info->deepcc, 0, sizeof(info->deepcc));
+		info->deepcc.avg_urtt = tp->deepcc_api.avg_urtt;
+		info->deepcc.min_rtt = tp->deepcc_api.min_urtt;
+		info->deepcc.cnt = tp->deepcc_api.cnt;
+		info->deepcc.avg_thr =
+			tp->deepcc_api.avg_thr * tp->mss_cache * USEC_PER_SEC >>
+			THR_SCALE_DEEPCC;
+		info->deepcc.thr_cnt = tp->deepcc_api.thr_cnt;
+		info->deepcc.cwnd = tp->snd_cwnd;
+		info->deepcc.pacing_rate = sk->sk_pacing_rate;
+		info->deepcc.lost_bytes =
+			(tp->lost - tp->deepcc_api.pre_lost) * tp->mss_cache;
+		info->deepcc.srtt_us =
+			tp->srtt_us; /* smoothed round trip time << 3 in usecs */
+		info->deepcc.snd_ssthresh =
+			tp->snd_ssthresh; /* Slow start size threshold		*/
+		info->deepcc.packets_out =
+			tp->packets_out; /* Packets which are "in flight"	*/
+		info->deepcc.retrans_out =
+			tp->retrans_out; /* Retransmitted packets out		*/
+		info->deepcc.max_packets_out =
+			tp->max_packets_out; /* max packets_out in last window */
+		info->deepcc.mss_cache =
+			tp->mss_cache; /* max packets_out in last window */
+
+		*attr = INET_DIAG_DEEPCCINFO;
+		tp->deepcc_api.cnt = 0;
+		tp->deepcc_api.avg_urtt = 0;
+		tp->deepcc_api.thr_cnt = 0;
+		tp->deepcc_api.avg_thr = 0;
+		tp->deepcc_api.pre_lost = tp->lost;
+
+		return sizeof(info->deepcc);
+	}
+	return 0;
+}
+
+static void deepcc_update_pacing_rate(struct sock *sk)
+{
+	const struct tcp_sock *tp = tcp_sk(sk);
+	u64 rate;
+	cmpxchg(&sk->sk_pacing_status, SK_PACING_NONE, SK_PACING_NEEDED);
+
+	rate = tcp_mss_to_mtu(sk, tcp_sk(sk)->mss_cache); //
+
+	rate *= USEC_PER_SEC;
+
+	rate *= max(tp->snd_cwnd, tp->packets_out);
+
+	if (likely(tp->srtt_us >> 3))
+		do_div(rate, tp->srtt_us >> 3);
+
+	/* ACCESS_ONCE() is needed because sch_fq fetches sk_pacing_rate
+	 * without any lock. We want to make sure compiler wont store
+	 * intermediate values in this location.
+	 */
+	WRITE_ONCE(sk->sk_pacing_rate, min_t(u64, rate, sk->sk_max_pacing_rate));
+}
+
+void deepcc_update_cwnd(struct sock *sk)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	tp->snd_cwnd = max(tp->snd_cwnd, tp->cwnd_min);
+	tp->snd_cwnd = min(tp->snd_cwnd, tp->snd_cwnd_clamp);
+	if (tp->deepcc_enable > 1)
+		deepcc_update_pacing_rate(sk);
+}
+
+void deepcc_get_rate_sample(struct sock *sk,
+				   const struct rate_sample *rs)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+	u64 bw;
+	if (rs->delivered < 0 || rs->interval_us <= 0)
+		return; /* Not a valid observation */
+
+	bw = (u64)rs->delivered * THR_UNIT_DEEPCC;
+	do_div(bw, rs->interval_us);
+	tp->deepcc_api.avg_thr =
+		tp->deepcc_api.avg_thr * tp->deepcc_api.thr_cnt + bw;
+	tp->deepcc_api.thr_cnt = tp->deepcc_api.thr_cnt + 1;
+	do_div(tp->deepcc_api.avg_thr, tp->deepcc_api.thr_cnt);
+}
+
+void deepcc_pkts_acked(struct sock *sk, const struct ack_sample *sample)
+{
+	struct tcp_sock *tp = tcp_sk(sk);
+
+	/* Some calls are for duplicates without timetamps */
+	if (sample->rtt_us < 0)
+		return;
+
+	if (tp->deepcc_api.min_urtt == 0 ||
+	    tp->deepcc_api.min_urtt > sample->rtt_us)
+		tp->deepcc_api.min_urtt = sample->rtt_us;
+	if (sample->rtt_us > 0) {
+		u64 tmp_avg = 0;
+		u64 tmp2_avg = 0;
+		tmp_avg = (tp->deepcc_api.cnt) * tp->deepcc_api.avg_urtt +
+			  sample->rtt_us;
+		tp->deepcc_api.cnt++;
+		tmp2_avg = tp->deepcc_api.cnt;
+	tmp2_avg = tmp_avg / tp->deepcc_api.cnt;
+		tp->deepcc_api.avg_urtt = (u32)(tmp2_avg);
+	}
+}
+//END
\ No newline at end of file
diff --git a/net/ipv4/tcp_input.c b/net/ipv4/tcp_input.c
index 2195ba488142..e9e4825fe4db 100644
--- a/net/ipv4/tcp_input.c
+++ b/net/ipv4/tcp_input.c
@@ -3421,6 +3421,15 @@ static int tcp_clean_rtx_queue(struct sock *sk, const struct sk_buff *ack_skb,
 		 */
 		flag |= FLAG_SET_XMIT_TIMER;  /* set TLP or RTO timer */
 	}
+	/* DeepCC sampling: Some schemes such as BBR does not have ->pkt_acked function! */
+	// So let's don't use next if{} ;)
+	// struct net *net = sock_net(sk);
+	if (tp->deepcc_enable || sysctl_tcp_deepcc_enable) {
+		struct ack_sample sample = { .pkts_acked = pkts_acked,
+					     .rtt_us = sack->rate->rtt_us,
+					     .in_flight = sample.in_flight };
+		deepcc_pkts_acked(sk,&sample);
+	}
 
 	if (icsk->icsk_ca_ops->pkts_acked) {
 		struct ack_sample sample = { .pkts_acked = pkts_acked,
@@ -3512,7 +3521,12 @@ static void tcp_cong_control(struct sock *sk, u32 ack, u32 acked_sacked,
 			     int flag, const struct rate_sample *rs)
 {
 	const struct inet_connection_sock *icsk = inet_csk(sk);
-
+	
+	/* DeepCC: Update Throughput samples */
+	struct tcp_sock *tp = tcp_sk(sk);
+	if (tp->deepcc_enable || sysctl_tcp_deepcc_enable)
+		deepcc_get_rate_sample(sk,rs);
+	/* END */ 
 	if (icsk->icsk_ca_ops->cong_control) {
 		icsk->icsk_ca_ops->cong_control(sk, rs);
 		return;
@@ -3525,6 +3539,13 @@ static void tcp_cong_control(struct sock *sk, u32 ack, u32 acked_sacked,
 		/* Advance cwnd if state allows */
 		tcp_cong_avoid(sk, ack, acked_sacked);
 	}
+
+	/* DeepCC: Time to apply the DRL-Agent's action */
+	if (tp->deepcc_enable || sysctl_tcp_deepcc_enable) {
+		deepcc_update_cwnd(sk);
+		return;
+	}
+
 	tcp_update_pacing_rate(sk);
 }
 
@@ -6090,6 +6111,10 @@ void tcp_init_transfer(struct sock *sk, int bpf_op, struct sk_buff *skb)
 	/* Initialize congestion control unless BPF initialized it already: */
 	if (!icsk->icsk_ca_initialized)
 		tcp_init_congestion_control(sk);
+
+	/* DeepCC Initialization */
+	deepcc_init(sk);
+	
 	tcp_init_buffer_space(sk);
 }
 
